{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nangs.pde import PDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# solutions\n",
    "\n",
    "> This module contains some commo9n function approximators to solve PDEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import torch\n",
    "\n",
    "def get_activation(a):\n",
    "    if a == \"relu\": return torch.nn.ReLU(inplace=True)\n",
    "    elif a == \"sigmoid\": return torch.nn.Sigmoid()\n",
    "    elif a == \"softsign\": return torch.nn.Softsign()\n",
    "    else: raise Exception(\"invalid activation\")\n",
    "\n",
    "def block(i, o, a):\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Linear(i, o), \n",
    "        get_activation(a)\n",
    "    )\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, inputs, outputs, layers, neurons, activations=\"softsign\"):\n",
    "        super().__init__()\n",
    "        self.fc_in = block(inputs, neurons, activations)\n",
    "        self.fc_hidden = torch.nn.ModuleList()\n",
    "        for layer in range(layers):\n",
    "            self.fc_hidden.append(block(neurons, neurons, activations))\n",
    "        self.fc_out = torch.nn.Linear(neurons, outputs, activations)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc_in(x)\n",
    "        for layer in self.fc_hidden:\n",
    "            x = layer(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc_in): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (fc_hidden): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (fc_out): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pde = PDE(inputs=['x', 't'], outputs=['p'])\n",
    "\n",
    "# add values and bocos\n",
    "\n",
    "mlp = MLP(pde.n_inputs, pde.n_outputs, 3, 100)\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.01)\n",
    "\n",
    "pde.compile(mlp, optimizer)\n",
    "\n",
    "pde.solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0613],\n",
       "        [-0.0360]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input = torch.tensor([[1, 2], [3, 4]]).float()\n",
    "test_output = pde.solution(test_input)\n",
    "test_output"
   ]
  },
  {9.800,00
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
